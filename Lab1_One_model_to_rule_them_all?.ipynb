{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NinaNusb/Multilingual_NLP/blob/main/Lab1_One_model_to_rule_them_all%3F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One model to rule them all?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PDlBwq2A_okk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vybJfcUPI2p",
        "outputId": "f90c2e3b-e557-41ac-ecb8-f0110f7ce9bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prnK08cagsI_",
        "outputId": "2442e042-6de2-45d8-9a4c-50d35214936c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyicu in /usr/local/lib/python3.10/dist-packages (2.11)\n",
            "Requirement already satisfied: pycld2 in /usr/local/lib/python3.10/dist-packages (0.41)\n",
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.10/dist-packages (2.0.6)\n",
            "Requirement already satisfied: polyglot in /usr/local/lib/python3.10/dist-packages (16.7.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
            "  Using cached https://github.com/kpu/kenlm/archive/master.zip\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install pyicu\n",
        "!pip install pycld2\n",
        "!pip install morfessor\n",
        "!pip install polyglot\n",
        "!pip install sentencepiece\n",
        "! pip install https://github.com/kpu/kenlm/archive/master.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kenlm\n",
        "print(dir(kenlm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIQNtmJ1WvId",
        "outputId": "5b5b955f-c596-4900-83bd-6b0c8c6e0c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ARPALoadComplain', 'Config', 'FullScoreReturn', 'LanguageModel', 'LoadMethod', 'Model', 'State', '__builtins__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '__test__', 'os']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kpu/kenlm.git\n",
        "%cd kenlm\n",
        "!python setup.py develop\n",
        "!mkdir -p build\n",
        "%cd build\n",
        "!cmake ..\n",
        "!make -j 4"
      ],
      "metadata": {
        "id": "GcHacCkoZyVY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "543012fd-abfc-4a13-8181-d6cf4ca9da38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'kenlm'...\n",
            "remote: Enumerating objects: 14161, done.\u001b[K\n",
            "remote: Counting objects: 100% (474/474), done.\u001b[K\n",
            "remote: Compressing objects: 100% (329/329), done.\u001b[K\n",
            "remote: Total 14161 (delta 162), reused 406 (delta 131), pack-reused 13687\u001b[K\n",
            "Receiving objects: 100% (14161/14161), 5.91 MiB | 11.06 MiB/s, done.\n",
            "Resolving deltas: 100% (8042/8042), done.\n",
            "/content/kenlm/build/kenlm\n",
            "Will build with KenLM max_order set to 6\n",
            "running develop\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  easy_install.initialize_options(self)\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running egg_info\n",
            "creating kenlm.egg-info\n",
            "writing kenlm.egg-info/PKG-INFO\n",
            "writing dependency_links to kenlm.egg-info/dependency_links.txt\n",
            "writing top-level names to kenlm.egg-info/top_level.txt\n",
            "writing manifest file 'kenlm.egg-info/SOURCES.txt'\n",
            "reading manifest file 'kenlm.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "adding license file 'COPYING'\n",
            "adding license file 'COPYING.3'\n",
            "adding license file 'COPYING.LESSER.3'\n",
            "writing manifest file 'kenlm.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Could NOT find Eigen3 (missing: Eigen3_DIR)\n",
            "\u001b[0mCMake Deprecation Warning at python/BuildStandalone.cmake:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "Call Stack (most recent call first):\n",
            "  CMakeLists.txt:31 (include)\n",
            "\n",
            "\u001b[0m\n",
            "-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\")  \n",
            "-- Found BZip2: /usr/lib/x86_64-linux-gnu/libbz2.so (found version \"1.0.8\") \n",
            "-- Looking for BZ2_bzCompressInit\n",
            "-- Looking for BZ2_bzCompressInit - found\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Found LibLZMA: /usr/lib/x86_64-linux-gnu/liblzma.so (found version \"5.2.5\") \n",
            "-- Configuring done (3.0s)\n",
            "-- Generating done (0.1s)\n",
            "-- Build files have been written to: /content/kenlm/build/kenlm/build/temp.linux-x86_64-cpython-310\n",
            "[  2%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/lm/bhiksha.cc.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/lm/binary_format.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/lm/config.cc.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/lm/lm_exception.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/lm/model.cc.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/lm/quantize.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/lm/read_arpa.cc.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/lm/search_hashed.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/lm/search_trie.cc.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/lm/sizes.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/lm/trie.cc.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/lm/trie_sort.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/lm/value_build.cc.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/lm/virtual_interface.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/lm/vocab.cc.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/python/score_sentence.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/bit_packing.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/double-conversion/bignum-dtoa.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/double-conversion/bignum.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/double-conversion/cached-powers.cc.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/double-conversion/double-to-string.cc.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/double-conversion/fast-dtoa.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/double-conversion/fixed-dtoa.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/double-conversion/string-to-double.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/double-conversion/strtod.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/ersatz_progress.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/exception.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/file.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/file_piece.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/float_to_string.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/integer_to_string.cc.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/mmap.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/murmur_hash.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/parallel_read.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/pool.cc.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/read_compressed.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/scoped.cc.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/spaces.cc.o\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/string_piece.cc.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object CMakeFiles/kenlm.dir/util/usage.cc.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared library /content/kenlm/build/kenlm/libkenlm.so\u001b[0m\n",
            "[100%] Built target kenlm\n",
            "building 'kenlm' extension\n",
            "creating build/temp.linux-x86_64-cpython-310/lm\n",
            "creating build/temp.linux-x86_64-cpython-310/python\n",
            "creating build/temp.linux-x86_64-cpython-310/util\n",
            "creating build/temp.linux-x86_64-cpython-310/util/double-conversion\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c lm/bhiksha.cc -o build/temp.linux-x86_64-cpython-310/lm/bhiksha.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c lm/binary_format.cc -o build/temp.linux-x86_64-cpython-310/lm/binary_format.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "\u001b[01m\u001b[Klm/binary_format.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid lm::ngram::BinaryFormat::FinishFile(const lm::ngram::Config&, lm::ngram::ModelType, unsigned int, const std::vector<long unsigned int>&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Klm/binary_format.cc:261:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid* memset(void*, int, size_t)\u001b[m\u001b[K’ clearing an object of type ‘\u001b[01m\u001b[Kstruct lm::ngram::Parameters\u001b[m\u001b[K’ with no trivial copy-assignment; use assignment or value-initialization instead [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wclass-memaccess\u0007-Wclass-memaccess\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  261 |   \u001b[01;35m\u001b[Kmemset(&params, 0, sizeof(Parameters))\u001b[m\u001b[K;\n",
            "      |   \u001b[01;35m\u001b[K~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Klm/binary_format.cc:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Klm/binary_format.hh:42:8:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K‘\u001b[01m\u001b[Kstruct lm::ngram::Parameters\u001b[m\u001b[K’ declared here\n",
            "   42 | struct \u001b[01;36m\u001b[KParameters\u001b[m\u001b[K {\n",
            "      |        \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c lm/config.cc -o build/temp.linux-x86_64-cpython-310/lm/config.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c lm/lm_exception.cc -o build/temp.linux-x86_64-cpython-310/lm/lm_exception.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c lm/model.cc -o build/temp.linux-x86_64-cpython-310/lm/model.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c lm/quantize.cc -o build/temp.linux-x86_64-cpython-310/lm/quantize.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c lm/read_arpa.cc -o build/temp.linux-x86_64-cpython-310/lm/read_arpa.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c lm/search_hashed.cc -o build/temp.linux-x86_64-cpython-310/lm/search_hashed.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c lm/search_trie.cc -o build/temp.linux-x86_64-cpython-310/lm/search_trie.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c lm/sizes.cc -o build/temp.linux-x86_64-cpython-310/lm/sizes.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c lm/trie.cc -o build/temp.linux-x86_64-cpython-310/lm/trie.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c lm/trie_sort.cc -o build/temp.linux-x86_64-cpython-310/lm/trie_sort.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c lm/value_build.cc -o build/temp.linux-x86_64-cpython-310/lm/value_build.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c lm/virtual_interface.cc -o build/temp.linux-x86_64-cpython-310/lm/virtual_interface.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c lm/vocab.cc -o build/temp.linux-x86_64-cpython-310/lm/vocab.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c python/kenlm.cpp -o build/temp.linux-x86_64-cpython-310/python/kenlm.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c python/score_sentence.cc -o build/temp.linux-x86_64-cpython-310/python/score_sentence.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/bit_packing.cc -o build/temp.linux-x86_64-cpython-310/util/bit_packing.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/double-conversion/bignum-dtoa.cc -o build/temp.linux-x86_64-cpython-310/util/double-conversion/bignum-dtoa.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/double-conversion/bignum.cc -o build/temp.linux-x86_64-cpython-310/util/double-conversion/bignum.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/double-conversion/cached-powers.cc -o build/temp.linux-x86_64-cpython-310/util/double-conversion/cached-powers.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/double-conversion/double-to-string.cc -o build/temp.linux-x86_64-cpython-310/util/double-conversion/double-to-string.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/double-conversion/fast-dtoa.cc -o build/temp.linux-x86_64-cpython-310/util/double-conversion/fast-dtoa.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/double-conversion/fixed-dtoa.cc -o build/temp.linux-x86_64-cpython-310/util/double-conversion/fixed-dtoa.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/double-conversion/string-to-double.cc -o build/temp.linux-x86_64-cpython-310/util/double-conversion/string-to-double.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/double-conversion/strtod.cc -o build/temp.linux-x86_64-cpython-310/util/double-conversion/strtod.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/ersatz_progress.cc -o build/temp.linux-x86_64-cpython-310/util/ersatz_progress.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/exception.cc -o build/temp.linux-x86_64-cpython-310/util/exception.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/file.cc -o build/temp.linux-x86_64-cpython-310/util/file.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/file_piece.cc -o build/temp.linux-x86_64-cpython-310/util/file_piece.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/float_to_string.cc -o build/temp.linux-x86_64-cpython-310/util/float_to_string.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/integer_to_string.cc -o build/temp.linux-x86_64-cpython-310/util/integer_to_string.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/mmap.cc -o build/temp.linux-x86_64-cpython-310/util/mmap.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/murmur_hash.cc -o build/temp.linux-x86_64-cpython-310/util/murmur_hash.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/parallel_read.cc -o build/temp.linux-x86_64-cpython-310/util/parallel_read.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/pool.cc -o build/temp.linux-x86_64-cpython-310/util/pool.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/read_compressed.cc -o build/temp.linux-x86_64-cpython-310/util/read_compressed.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/scoped.cc -o build/temp.linux-x86_64-cpython-310/util/scoped.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/spaces.cc -o build/temp.linux-x86_64-cpython-310/util/spaces.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/string_piece.cc -o build/temp.linux-x86_64-cpython-310/util/string_piece.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I. -I/usr/include/python3.10 -c util/usage.cc -o build/temp.linux-x86_64-cpython-310/util/usage.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_CLOCKGETTIME -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "x86_64-linux-gnu-gcc -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/lm/bhiksha.o build/temp.linux-x86_64-cpython-310/lm/binary_format.o build/temp.linux-x86_64-cpython-310/lm/config.o build/temp.linux-x86_64-cpython-310/lm/lm_exception.o build/temp.linux-x86_64-cpython-310/lm/model.o build/temp.linux-x86_64-cpython-310/lm/quantize.o build/temp.linux-x86_64-cpython-310/lm/read_arpa.o build/temp.linux-x86_64-cpython-310/lm/search_hashed.o build/temp.linux-x86_64-cpython-310/lm/search_trie.o build/temp.linux-x86_64-cpython-310/lm/sizes.o build/temp.linux-x86_64-cpython-310/lm/trie.o build/temp.linux-x86_64-cpython-310/lm/trie_sort.o build/temp.linux-x86_64-cpython-310/lm/value_build.o build/temp.linux-x86_64-cpython-310/lm/virtual_interface.o build/temp.linux-x86_64-cpython-310/lm/vocab.o build/temp.linux-x86_64-cpython-310/python/kenlm.o build/temp.linux-x86_64-cpython-310/python/score_sentence.o build/temp.linux-x86_64-cpython-310/util/bit_packing.o build/temp.linux-x86_64-cpython-310/util/double-conversion/bignum-dtoa.o build/temp.linux-x86_64-cpython-310/util/double-conversion/bignum.o build/temp.linux-x86_64-cpython-310/util/double-conversion/cached-powers.o build/temp.linux-x86_64-cpython-310/util/double-conversion/double-to-string.o build/temp.linux-x86_64-cpython-310/util/double-conversion/fast-dtoa.o build/temp.linux-x86_64-cpython-310/util/double-conversion/fixed-dtoa.o build/temp.linux-x86_64-cpython-310/util/double-conversion/string-to-double.o build/temp.linux-x86_64-cpython-310/util/double-conversion/strtod.o build/temp.linux-x86_64-cpython-310/util/ersatz_progress.o build/temp.linux-x86_64-cpython-310/util/exception.o build/temp.linux-x86_64-cpython-310/util/file.o build/temp.linux-x86_64-cpython-310/util/file_piece.o build/temp.linux-x86_64-cpython-310/util/float_to_string.o build/temp.linux-x86_64-cpython-310/util/integer_to_string.o build/temp.linux-x86_64-cpython-310/util/mmap.o build/temp.linux-x86_64-cpython-310/util/murmur_hash.o build/temp.linux-x86_64-cpython-310/util/parallel_read.o build/temp.linux-x86_64-cpython-310/util/pool.o build/temp.linux-x86_64-cpython-310/util/read_compressed.o build/temp.linux-x86_64-cpython-310/util/scoped.o build/temp.linux-x86_64-cpython-310/util/spaces.o build/temp.linux-x86_64-cpython-310/util/string_piece.o build/temp.linux-x86_64-cpython-310/util/usage.o -L/usr/lib/x86_64-linux-gnu -lstdc++ -lrt -lz -lbz2 -llzma -o build/lib.linux-x86_64-cpython-310/kenlm.cpython-310-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-cpython-310/kenlm.cpython-310-x86_64-linux-gnu.so -> \n",
            "Creating /usr/local/lib/python3.10/dist-packages/kenlm.egg-link (link to .)\n",
            "Removing kenlm 0.2.0 from easy-install.pth file\n",
            "Adding kenlm 0.2.0 to easy-install.pth file\n",
            "\n",
            "Installed /content/kenlm/build/kenlm\n",
            "Processing dependencies for kenlm==0.2.0\n",
            "Finished processing dependencies for kenlm==0.2.0\n",
            "/content/kenlm/build/kenlm/build\n",
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Could NOT find Eigen3 (missing: Eigen3_DIR)\n",
            "-- Found Boost: /usr/lib/x86_64-linux-gnu/cmake/Boost-1.74.0/BoostConfig.cmake (found suitable version \"1.74.0\", minimum required is \"1.41.0\") found components: program_options system thread unit_test_framework \n",
            "-- Found Threads: TRUE  \n",
            "-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\")  \n",
            "-- Found BZip2: /usr/lib/x86_64-linux-gnu/libbz2.so (found version \"1.0.8\") \n",
            "-- Looking for BZ2_bzCompressInit\n",
            "-- Looking for BZ2_bzCompressInit - found\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Found LibLZMA: /usr/lib/x86_64-linux-gnu/liblzma.so (found version \"5.2.5\") \n",
            "-- Looking for clock_gettime in rt\n",
            "-- Looking for clock_gettime in rt - found\n",
            "-- Configuring done (1.1s)\n",
            "-- Generating done (0.1s)\n",
            "-- Build files have been written to: /content/kenlm/build/kenlm/build\n",
            "[  1%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum-dtoa.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/cached-powers.cc.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum.cc.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fast-dtoa.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fixed-dtoa.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/strtod.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/double-to-string.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/string-to-double.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/count_records.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/chain.cc.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/io.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/line_input.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/multi_progress.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/rewindable_stream.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/bit_packing.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/ersatz_progress.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/exception.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file_piece.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/float_to_string.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/integer_to_string.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/mmap.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/murmur_hash.cc.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/parallel_read.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/pool.cc.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/read_compressed.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/scoped.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/spaces.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/string_piece.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/usage.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm_util.a\u001b[0m\n",
            "[ 38%] Built target kenlm_util\n",
            "[ 40%] \u001b[32mBuilding CXX object util/CMakeFiles/probing_hash_table_benchmark.dir/probing_hash_table_benchmark_main.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/arpa_io.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/phrase.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/bhiksha.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/binary_format.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/vocab.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/config.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/lm_exception.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/model.cc.o\u001b[0m\n",
            "[ 51%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_filter.a\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/quantize.cc.o\u001b[0m\n",
            "[ 52%] Built target kenlm_filter\n",
            "[ 53%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/read_arpa.cc.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_hashed.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_trie.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/sizes.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie_sort.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32m\u001b[1mLinking CXX executable ../bin/probing_hash_table_benchmark\u001b[0m\n",
            "[ 61%] Built target probing_hash_table_benchmark\n",
            "[ 62%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/value_build.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/virtual_interface.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/vocab.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/model_buffer.cc.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/print.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/renumber.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/size_option.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm.a\u001b[0m\n",
            "[ 71%] Built target kenlm\n",
            "[ 72%] \u001b[32mBuilding CXX object lm/CMakeFiles/fragment.dir/fragment_main.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object lm/CMakeFiles/query.dir/query_main.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object lm/CMakeFiles/build_binary.dir/build_binary_main.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm_benchmark.dir/kenlm_benchmark_main.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32m\u001b[1mLinking CXX executable ../bin/fragment\u001b[0m\n",
            "[ 77%] Built target fragment\n",
            "[ 78%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/adjust_counts.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32m\u001b[1mLinking CXX executable ../bin/build_binary\u001b[0m\n",
            "[ 80%] Built target build_binary\n",
            "[ 81%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/filter.dir/filter_main.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32m\u001b[1mLinking CXX executable ../bin/query\u001b[0m\n",
            "[ 82%] Built target query\n",
            "[ 83%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/phrase_table_vocab.dir/phrase_table_vocab_main.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/phrase_table_vocab\u001b[0m\n",
            "[ 86%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/corpus_count.cc.o\u001b[0m\n",
            "[ 86%] Built target phrase_table_vocab\n",
            "[ 87%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/initial_probabilities.cc.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/interpolate.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/output.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/pipeline.cc.o\u001b[0m\n",
            "[ 92%] \u001b[32m\u001b[1mLinking CXX executable ../bin/kenlm_benchmark\u001b[0m\n",
            "[ 92%] Built target kenlm_benchmark\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/filter\u001b[0m\n",
            "[ 93%] Built target filter\n",
            "[ 95%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_builder.a\u001b[0m\n",
            "[ 95%] Built target kenlm_builder\n",
            "[ 97%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/count_ngrams.dir/count_ngrams_main.cc.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/lmplz.dir/lmplz_main.cc.o\u001b[0m\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/lmplz\u001b[0m\n",
            "[ 98%] Built target lmplz\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/count_ngrams\u001b[0m\n",
            "[100%] Built target count_ngrams\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zi-wFLvXaUgM"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "from itertools import islice\n",
        "import polyglot\n",
        "from polyglot.text import Text, Word\n",
        "import os\n",
        "import kenlm\n",
        "import logging\n",
        "import subprocess\n",
        "import matplotlib.pyplot as plt\n",
        "import sentencepiece as spm\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating the corpora"
      ],
      "metadata": {
        "id": "Ff_XGPkE__B0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_PetCNvZ2h-"
      },
      "outputs": [],
      "source": [
        "# first extract sentences from articles and tokenize them\n",
        "ignore = [\"_NEWLINE_\", \"\\n_START_SECTION_\\n\", \"\\n_START_PARAGRAPH_\\n\", \"_START_ARTICLE_\"]\n",
        "\n",
        "# sentences = [Text(sentence) if not sentence.startswith(\"_\") else \"\" for sentence in text for text in sample]\n",
        "# sentences2 = [(Text(sentence)).sentences if sentence not in ignore else \"\" for sentence in sample]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of ISO 639-1 language codes available in the wiki40b corpus\n",
        "lang_codes = [\"ar\", \"bg\", \"ca\", \"cs\", \"da\", \"de\", \"el\", \"en\", \"es\", \"et\", \"fa\", \"fi\", \"fr\", \"he\", \"hi\", \"hr\", \"hu\", \"id\", \"it\", \"ja\", \"ko\", \"lt\", \"lv\", \"ms\", \"nl\", \"no\", \"pl\", \"pt\", \"ro\", \"ru\", \"sk\", \"sl\", \"sr\", \"sv\", \"th\", \"tl\", \"tr\", \"uk\", \"vi\", \"zh-cn\", \"zh-tw\"]\n",
        "all_data = pd.DataFrame({\"languages\": lang_codes})"
      ],
      "metadata": {
        "id": "T1-AXV_iqhpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.getLogger('polyglot.detect.base').setLevel(logging.ERROR)\n",
        "\n",
        "def tokenize_sentences_polyglot(text):\n",
        "    sentences = Text(text).sentences\n",
        "    return [str(sentence) for sentence in sentences]\n",
        "\n",
        "def tokenize_sentences_sentencePiece(text):\n",
        "    sp = spm.SentencePieceProcessor()\n",
        "    # Split text into sentences (customize as needed)\n",
        "    sentences = text.split('.')\n",
        "    tokenized_sentences = [\n",
        "        # Tokenize the sentence\n",
        "        ' '.join(sp.encode(sentence, out_type=str)) for sentence in sentences]\n",
        "    return tokenized_sentences\n",
        "\n",
        "def tokenize_words_sentencePiece(model_file, lang, text):\n",
        "    sp = spm.SentencePieceProcessor(model_file + lang + \".model\")\n",
        "    tokens = sp.encode(text, out_type=str)\n",
        "    return tokens\n",
        "\n",
        "# Dictionary to map tokenizer names to functions\n",
        "tokenization_functions = {\n",
        "    \"polyglot\": tokenize_sentences_polyglot,\n",
        "    \"sentencepiece\": tokenize_sentences_sentencePiece,\n",
        "}"
      ],
      "metadata": {
        "id": "ghMZIpmUu8K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unique_sentences(lang, nb_articles, tokenizer, split):\n",
        "  # Get the tokenization function based on the tokenizer argument\n",
        "  tokenize_sentences = tokenization_functions.get(tokenizer)\n",
        "  if tokenize_sentences is None:\n",
        "     raise ValueError(\"Invalid tokenizer\")\n",
        "  # Load the dataset for the current language with the appropriate split\n",
        "  ds = tfds.load(f\"wiki40b/{lang}\", split=split, data_dir=\"gs://tfds-data/datasets\")\n",
        "  # Sample a subset of articles (adjust the number as needed)\n",
        "  sampled_articles = [ex[\"text\"].numpy().decode(\"utf-8\") for ex in islice(ds.shuffle(buffer_size=10_000), nb_articles)]\n",
        "   # Tokenize sentences using Polyglot and remove duplicates\n",
        "  unique_sentences = list(set(sentence for article in sampled_articles for sentence in tokenize_sentences(article)))\n",
        "  # Ensure you have enough unique sentences for train and test sets\n",
        "  return unique_sentences"
      ],
      "metadata": {
        "id": "BPJLJ2nYmJU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_test_sets(lang, unique_sentences, train_size, test_size):\n",
        "  # Split the sentences into train and test sets\n",
        "  train_set = unique_sentences[:train_size]\n",
        "  test_set = unique_sentences[train_size:train_size+test_size]\n",
        "  train_sets[lang] = train_set\n",
        "  test_sets[lang] = test_set\n",
        "  return train_sets, test_sets"
      ],
      "metadata": {
        "id": "hg1HFk3G0vKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each languages of the corpus extract a train set of 40,000 sentences and a test set of 3,000 sentences. Sentences must be unique (i.e. if there are several occurrences of an identical sentence, they must all be removed but one). Using polyglot tokenize all datasets into words. Save each dataset into a separate text file (one sentence per line) using consistent names to be able to automate the LM estimation."
      ],
      "metadata": {
        "id": "AXrzzTBeAPoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 40_000\n",
        "test_size = 3_000\n",
        "nb_articles = 10_000\n",
        "\n",
        "train_sets = {}\n",
        "test_sets = {}\n",
        "\n",
        "for lang in lang_codes:\n",
        "    unique_sentences = get_unique_sentences(lang, nb_articles, tokenizer=\"polyglot\", split=\"test\")\n",
        "    if len(unique_sentences) >= (train_size + test_size):\n",
        "        train_sets, test_sets = get_train_test_sets(lang, unique_sentences, train_size, test_size)\n",
        "        print(f\"Complete sample for {lang}\")\n",
        "    else:\n",
        "        # Not enough unique sentences for both sets, switch to \"train\" split\n",
        "        unique_sentences = get_unique_sentences(lang, nb_articles, tokenizer=\"polyglot\", split=\"train\")\n",
        "\n",
        "        # Check if there are enough unique sentences for both train and test sets\n",
        "        if len(unique_sentences) >= (train_size + test_size):\n",
        "            train_sets, test_sets = get_train_test_sets(lang, unique_sentences, train_size, test_size)\n",
        "            print(f\"Complete sample for {lang} (using 'train' split)\")\n",
        "        else:\n",
        "            available_unique_sentences = len(unique_sentences)\n",
        "            print(f\"Available unique sentences for {lang}: {available_unique_sentences}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cyqi7mWBlqYs",
        "outputId": "a99b7d2a-5923-4340-f352-abb1751e7a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complete sample for ar\n",
            "Complete sample for bg\n",
            "Complete sample for ca\n",
            "Complete sample for cs\n",
            "Complete sample for da\n",
            "Complete sample for de\n",
            "Complete sample for el\n",
            "Complete sample for en\n",
            "Complete sample for es\n",
            "Complete sample for et\n",
            "Complete sample for fa\n",
            "Complete sample for fi\n",
            "Complete sample for fr\n",
            "Complete sample for he\n",
            "Complete sample for hi\n",
            "Complete sample for hr\n",
            "Complete sample for hu\n",
            "Complete sample for id\n",
            "Complete sample for it\n",
            "Complete sample for ja\n",
            "Complete sample for ko\n",
            "Complete sample for lt\n",
            "Complete sample for lv (using 'train' split)\n",
            "Complete sample for ms\n",
            "Complete sample for nl\n",
            "Complete sample for no\n",
            "Complete sample for pl\n",
            "Complete sample for pt\n",
            "Complete sample for ro\n",
            "Complete sample for ru\n",
            "Complete sample for sk\n",
            "Complete sample for sl\n",
            "Complete sample for sr\n",
            "Complete sample for sv\n",
            "Complete sample for th (using 'train' split)\n",
            "Complete sample for tl (using 'train' split)\n",
            "Complete sample for tr\n",
            "Complete sample for uk\n",
            "Complete sample for vi\n",
            "Complete sample for zh-cn\n",
            "Complete sample for zh-tw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(lang_codes))\n",
        "print(len(train_sets))\n",
        "print(len(test_sets))"
      ],
      "metadata": {
        "id": "3Ot2tAfvxoB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a42b89-ccdc-4921-f26b-dea08e0240e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41\n",
            "41\n",
            "41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWP9fQS6vnxJ"
      },
      "outputs": [],
      "source": [
        "# Create training set of 40,000 sentences and a test set of 3,000 sentences OR LARGER\n",
        "def create_train_test_sets(lang_codes, set_size, nb_articles, split):\n",
        "  sets = {}\n",
        "  for lang_code in lang_codes:\n",
        "      # Load the dataset for the current language\n",
        "      ds = tfds.load(f\"wiki40b/{lang_code}\", split= split, data_dir=\"gs://tfds-data/datasets\")\n",
        "\n",
        "      # Sample a subset of articles (adjust the number as needed)\n",
        "      sampled_articles = [ex[\"text\"].numpy().decode(\"utf-8\") for ex in islice(ds.shuffle(buffer_size=10_000), nb_articles)]\n",
        "      # TODO: if not sentence.startswith(\"_\") else \"\"\n",
        "      # Tokenize sentences using Polyglot and remove duplicates\n",
        "      unique_sentences = list(set(sentence for article in sampled_articles for sentence in tokenize_sentences(article)))\n",
        "      # Ensure you have enough unique sentences for train and test sets\n",
        "      if len(unique_sentences) >= set_size:\n",
        "          dataset = unique_sentences[:set_size]\n",
        "\n",
        "          # Store the train and test sets in the dictionaries\n",
        "          sets[lang_code] = dataset\n",
        "          print(f\"Complete sample for {lang_code}\")\n",
        "      else:\n",
        "          available_unique_sentences = len(unique_sentences)\n",
        "          print(f\"Available unique sentences for {lang_code}: {available_unique_sentences}\")\n",
        "  return sets\n",
        "\n",
        "# train_sets = create_train_test_sets(lang_codes, train_size, nb_articles, split=\"train\")\n",
        "# test_sets = create_train_test_sets(lang_codes, test_size, nb_articles, split=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLc70mVL1lKA"
      },
      "outputs": [],
      "source": [
        "input_dir = \"/content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EBW07Djhfsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "492ed4ba-e317-4234-d4e5-9352eefe5475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ar\n",
            "Processing bg\n",
            "Processing ca\n",
            "Processing cs\n",
            "Processing da\n",
            "Processing de\n",
            "Processing el\n",
            "Processing en\n",
            "Processing es\n",
            "Processing et\n",
            "Processing fa\n",
            "Processing fi\n",
            "Processing fr\n",
            "Processing he\n",
            "Processing hi\n",
            "Processing hr\n",
            "Processing hu\n",
            "Processing id\n",
            "Processing it\n",
            "Processing ja\n",
            "Processing ko\n",
            "Processing lt\n",
            "Processing lv\n",
            "Processing ms\n",
            "Processing nl\n",
            "Processing no\n",
            "Processing pl\n",
            "Processing pt\n",
            "Processing ro\n",
            "Processing ru\n",
            "Processing sk\n",
            "Processing sl\n",
            "Processing sr\n",
            "Processing sv\n",
            "Processing th\n",
            "Processing tl\n",
            "Processing tr\n",
            "Processing uk\n",
            "Processing vi\n",
            "Processing zh-cn\n",
            "Processing zh-tw\n"
          ]
        }
      ],
      "source": [
        "# Using polyglot tokenize all datasets into words. Save each dataset into a separate text file (one sentence per line) using consistent names to be able to automate the LM estimation\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(input_dir, exist_ok=True)\n",
        "# Tokenize and save train datasets\n",
        "for lang_code, train_set in train_sets.items():\n",
        "    print(f\"Processing {lang_code}\")\n",
        "    with open(os.path.join(input_dir, f\"train_{lang_code}.txt\"), \"w\", encoding=\"utf-8\") as file:\n",
        "        for sentence in train_set:\n",
        "            tokens = Text(sentence).words\n",
        "            file.write(\" \".join(tokens) + \"\\n\")\n",
        "\n",
        "# Tokenize and save test datasets\n",
        "for lang_code, test_set in test_sets.items():\n",
        "    with open(os.path.join(input_dir, f\"test_{lang_code}.txt\"), \"w\", encoding=\"utf-8\") as file:\n",
        "        for sentence in test_set:\n",
        "            tokens = Text(sentence).words\n",
        "            file.write(\" \".join(tokens) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the files' content\n",
        "def read_first_lines(file_path, num_lines):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = []\n",
        "        for _ in range(num_lines):\n",
        "            line = file.readline()\n",
        "            if not line:\n",
        "                break  # End of file reached\n",
        "            lines.append(line.strip())\n",
        "    return lines\n",
        "\n",
        "file_path = input_dir + 'test_de.txt'\n",
        "first_lines = read_first_lines(file_path, 5)\n",
        "for line in first_lines:\n",
        "    print(line)"
      ],
      "metadata": {
        "id": "S3nMDrrnziyY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6718d7f-c690-4915-c095-d128e2eab2de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dazu zählt u . a . die Erschließung von großflächigen Industrie - und Gewerbegebieten .\n",
            "Münzgeschichtliche Zusammenhänge\n",
            "Dezember 2017 mit 69 von 126 Stimmen in das Amt gewählt und anschließend vereidigt .\n",
            "Sokratis war der Kapitän der griechischen U - 19 - Nationalmannschaft , mit der er bei der U - 19 - Europameisterschaft 2007 in Österreich und der Schweiz Vize - Europameister wurde , verpasste jedoch aufgrund einer Gelbsperre das Finale gegen Spanien .\n",
            "Das war damals eine Technologie , der wachsende Bedeutung beigemessen wurde .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS5bu-DriEWg"
      },
      "source": [
        "## Extracting morphological information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBnCnD0ug4Rk"
      },
      "outputs": [],
      "source": [
        "def calculate_ttr(tokens):\n",
        "    unique_words = set(tokens)\n",
        "    ttr = len(unique_words) / len(tokens)\n",
        "    return ttr\n",
        "\n",
        "# Dictionary to store TTR values for each dataset\n",
        "ttr_values_kenlm = {}\n",
        "ttr_list_kenlm = []\n",
        "\n",
        "# Iterate through the files in the input directory\n",
        "for lang in lang_codes:\n",
        "    # Read the content of the file and tokenize it\n",
        "    with open(os.path.join(input_dir, f\"train_{lang}.txt\"), \"r\", encoding=\"utf-8\") as file:\n",
        "        tokens_kenlm = file.read()\n",
        "\n",
        "        # Calculate TTR for the dataset\n",
        "        ttr_kenlm = calculate_ttr(tokens_kenlm)\n",
        "        # Store TTR value in the dictionary\n",
        "        ttr_values_kenlm[lang] = ttr_kenlm\n",
        "        ttr_list_kenlm.append(ttr_kenlm)\n",
        "\n",
        "all_data[\"ttr\"] = ttr_list_kenlm\n",
        "all_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiP4CzO9iXXh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4a09375e-93b7-4ec3-880d-e9a8502559a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   languages       ttr     morphology\n",
              "0         ar  0.140029   introflexive\n",
              "1         bg  0.119711       fusional\n",
              "2         ca  0.085750       fusional\n",
              "3         cs  0.167912       fusional\n",
              "4         da  0.120318       fusional\n",
              "5         de  0.138408       fusional\n",
              "6         el  0.112379       fusional\n",
              "7         en  0.081862       fusional\n",
              "8         es  0.083433       fusional\n",
              "9         et  0.200805  agglutinative\n",
              "10        fa  0.078423       fusional\n",
              "11        fi  0.236219  agglutinative\n",
              "12        fr  0.089337       fusional\n",
              "13        he  0.146773   introflexive\n",
              "14        hi  0.079520       fusional\n",
              "15        hr  0.154191       fusional\n",
              "16        hu  0.172005  agglutinative\n",
              "17        id  0.092668      isolating\n",
              "18        it  0.093626       fusional\n",
              "19        ja  0.052653  agglutinative\n",
              "20        ko  0.260542  agglutinative\n",
              "21        lt  0.169705       fusional\n",
              "22        lv  0.148228       fusional\n",
              "23        ms  0.082980      isolating\n",
              "24        nl  0.109410       fusional\n",
              "25        no  0.127935       fusional\n",
              "26        pl  0.167044       fusional\n",
              "27        pt  0.083124       fusional\n",
              "28        ro  0.100559       fusional\n",
              "29        ru  0.166875       fusional\n",
              "30        sk  0.167752       fusional\n",
              "31        sl  0.147444       fusional\n",
              "32        sr  0.164424       fusional\n",
              "33        sv  0.140271       fusional\n",
              "34        th  0.029789      isolating\n",
              "35        tl  0.089414      isolating\n",
              "36        tr  0.180305  agglutinative\n",
              "37        uk  0.165838       fusional\n",
              "38        vi  0.037888      isolating\n",
              "39     zh-cn  0.048717      isolating\n",
              "40     zh-tw  0.056662      isolating"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8b00b1a-3f67-4dfa-abe1-39fbf2bf01c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>languages</th>\n",
              "      <th>ttr</th>\n",
              "      <th>morphology</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ar</td>\n",
              "      <td>0.140029</td>\n",
              "      <td>introflexive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bg</td>\n",
              "      <td>0.119711</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ca</td>\n",
              "      <td>0.085750</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cs</td>\n",
              "      <td>0.167912</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>da</td>\n",
              "      <td>0.120318</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>de</td>\n",
              "      <td>0.138408</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>el</td>\n",
              "      <td>0.112379</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>en</td>\n",
              "      <td>0.081862</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>es</td>\n",
              "      <td>0.083433</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>et</td>\n",
              "      <td>0.200805</td>\n",
              "      <td>agglutinative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>fa</td>\n",
              "      <td>0.078423</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>fi</td>\n",
              "      <td>0.236219</td>\n",
              "      <td>agglutinative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>fr</td>\n",
              "      <td>0.089337</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>he</td>\n",
              "      <td>0.146773</td>\n",
              "      <td>introflexive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>hi</td>\n",
              "      <td>0.079520</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>hr</td>\n",
              "      <td>0.154191</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>hu</td>\n",
              "      <td>0.172005</td>\n",
              "      <td>agglutinative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>id</td>\n",
              "      <td>0.092668</td>\n",
              "      <td>isolating</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>it</td>\n",
              "      <td>0.093626</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>ja</td>\n",
              "      <td>0.052653</td>\n",
              "      <td>agglutinative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>ko</td>\n",
              "      <td>0.260542</td>\n",
              "      <td>agglutinative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>lt</td>\n",
              "      <td>0.169705</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>lv</td>\n",
              "      <td>0.148228</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ms</td>\n",
              "      <td>0.082980</td>\n",
              "      <td>isolating</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>nl</td>\n",
              "      <td>0.109410</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>no</td>\n",
              "      <td>0.127935</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>pl</td>\n",
              "      <td>0.167044</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>pt</td>\n",
              "      <td>0.083124</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>ro</td>\n",
              "      <td>0.100559</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>ru</td>\n",
              "      <td>0.166875</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>sk</td>\n",
              "      <td>0.167752</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>sl</td>\n",
              "      <td>0.147444</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>sr</td>\n",
              "      <td>0.164424</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>sv</td>\n",
              "      <td>0.140271</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>th</td>\n",
              "      <td>0.029789</td>\n",
              "      <td>isolating</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>tl</td>\n",
              "      <td>0.089414</td>\n",
              "      <td>isolating</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>tr</td>\n",
              "      <td>0.180305</td>\n",
              "      <td>agglutinative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>uk</td>\n",
              "      <td>0.165838</td>\n",
              "      <td>fusional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>vi</td>\n",
              "      <td>0.037888</td>\n",
              "      <td>isolating</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>zh-cn</td>\n",
              "      <td>0.048717</td>\n",
              "      <td>isolating</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>zh-tw</td>\n",
              "      <td>0.056662</td>\n",
              "      <td>isolating</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8b00b1a-3f67-4dfa-abe1-39fbf2bf01c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d8b00b1a-3f67-4dfa-abe1-39fbf2bf01c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d8b00b1a-3f67-4dfa-abe1-39fbf2bf01c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f97615a1-5fa1-4a7c-b6eb-316a2d9c0964\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f97615a1-5fa1-4a7c-b6eb-316a2d9c0964')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f97615a1-5fa1-4a7c-b6eb-316a2d9c0964 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ],
      "source": [
        "# Classify each language of the wiki40b corpus into one of the following four categories to characterize its morphology: isolating, fusional, introflexive and agglutinative.\n",
        "# use a typological database such as the WALS\n",
        "# Sample mapping of language codes to morphology categories\n",
        "\n",
        "morphology_dict = {\n",
        "    \"ar\": \"introflexive\", \"bg\": \"fusional\", \"ca\": \"fusional\", \"cs\": \"fusional\", \"da\": \"fusional\", \"de\": \"fusional\", \"el\": \"fusional\",\n",
        "    \"en\": \"fusional\", \"es\": \"fusional\", \"et\": \"agglutinative\", \"fa\": \"fusional\", \"fi\": \"agglutinative\", \"fr\": \"fusional\",\n",
        "    \"he\": \"introflexive\", \"hi\": \"fusional\", \"hr\": \"fusional\", \"hu\": \"agglutinative\", \"id\": \"isolating\", \"it\": \"fusional\",\n",
        "    \"ja\": \"agglutinative\", \"ko\": \"agglutinative\", \"lt\": \"fusional\", \"lv\": \"fusional\", \"ms\": \"isolating\", \"nl\": \"fusional\",\n",
        "    \"no\": \"fusional\", \"pl\": \"fusional\", \"pt\": \"fusional\", \"ro\": \"fusional\", \"ru\": \"fusional\", \"sk\": \"fusional\", \"sl\": \"fusional\",\n",
        "    \"sr\": \"fusional\", \"sv\": \"fusional\", \"th\": \"isolating\", \"tl\": \"isolating\", \"tr\": \"agglutinative\", \"uk\": \"fusional\", \"vi\": \"isolating\",\n",
        "    \"zh-cn\": \"isolating\", \"zh-tw\": \"isolating\"}\n",
        "\n",
        "# Create a dictionary to store the final morphology classifications\n",
        "morphology_classifications = {}\n",
        "morpho_list = []\n",
        "# Map language codes to morphology categories\n",
        "for lang, morphology_category in morphology_dict.items():\n",
        "  if lang in lang_codes:\n",
        "    morphology_classifications[lang] = morphology_category # TODO: do not add to the report\n",
        "    morpho_list.append(morphology_category)\n",
        "\n",
        "all_data[\"morphology\"] = morpho_list\n",
        "all_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5coXvpp9ipPt"
      },
      "source": [
        "## Training and evaluating language model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "id": "temLiRy8u93a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b26406f6-0986-4cac-eadf-b1a35df00b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mbin\u001b[0m/                            tokenizer_ja.vocab  tokenizer_sl.model\n",
            "CMakeCache.txt                  tokenizer_ko.model  tokenizer_sl.vocab\n",
            "\u001b[01;34mCMakeFiles\u001b[0m/                     tokenizer_ko.vocab  tokenizer_sr.model\n",
            "cmake_install.cmake             tokenizer_lt.model  tokenizer_sr.vocab\n",
            "kenlmConfig.cmake               tokenizer_lt.vocab  tokenizer_sv.model\n",
            "\u001b[01;34mlib\u001b[0m/                            tokenizer_lv.model  tokenizer_sv.vocab\n",
            "\u001b[01;34mlib.linux-x86_64-cpython-310\u001b[0m/   tokenizer_lv.vocab  tokenizer_th.model\n",
            "\u001b[01;34mlm\u001b[0m/                             tokenizer_ms.model  tokenizer_th.vocab\n",
            "Makefile                        tokenizer_ms.vocab  tokenizer_tl.model\n",
            "\u001b[01;34mtemp.linux-x86_64-cpython-310\u001b[0m/  tokenizer_nl.model  tokenizer_tl.vocab\n",
            "tokenizer_ar.model              tokenizer_nl.vocab  tokenizer_tr.model\n",
            "tokenizer_ar.vocab              tokenizer_no.model  tokenizer_tr.vocab\n",
            "tokenizer_bg.model              tokenizer_no.vocab  tokenizer_uk.model\n",
            "tokenizer_bg.vocab              tokenizer_pl.model  tokenizer_uk.vocab\n",
            "tokenizer_ca.model              tokenizer_pl.vocab  tokenizer_vi.model\n",
            "tokenizer_ca.vocab              tokenizer_pt.model  tokenizer_vi.vocab\n",
            "tokenizer_cs.model              tokenizer_pt.vocab  tokenizer_zh-cn.model\n",
            "tokenizer_cs.vocab              tokenizer_ro.model  tokenizer_zh-cn.vocab\n",
            "tokenizer_da.model              tokenizer_ro.vocab  tokenizer_zh-tw.model\n",
            "tokenizer_da.vocab              tokenizer_ru.model  tokenizer_zh-tw.vocab\n",
            "tokenizer_de.model              tokenizer_ru.vocab  \u001b[01;34mutil\u001b[0m/\n",
            "tokenizer_de.vocab              tokenizer_sk.model\n",
            "tokenizer_ja.model              tokenizer_sk.vocab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where ARPA models are stored\n",
        "# models_directory = \"https://github.com/kpu/kenlm/archive/master.zip\"\n",
        "arpa_dir = '/content/drive/MyDrive/Multilingual_NLP/Lab_1/kenlm/arpa_files'\n",
        "# arpa_dir = '/content/kenlm'\n",
        "\n",
        "for lang in lang_codes:\n",
        "    print(f'\\nProcessing: {lang}')\n",
        "    training_data_path = os.path.join(input_dir, f'train_{lang}.txt')\n",
        "    arpa_models_path = os.path.join(arpa_dir, f'{lang}.arpa')\n",
        "    # Define the command to train the language model\n",
        "    !./bin/lmplz -o 5 < $training_data_path > $arpa_models_path"
      ],
      "metadata": {
        "id": "3_Lu-Vwd8xaB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e169e22f-5096-4492-98a8-1d093d28bf63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: ar\n",
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_ar.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Unigram tokens 941406 types 131827\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:1581924 2:1062344704 3:1991896448 4:3187034112 5:4647758336\n",
            "Statistics:\n",
            "1 131827 D1=0.697349 D2=1.02739 D3+=1.42757\n",
            "2 601092 D1=0.864746 D2=1.18055 D3+=1.42246\n",
            "3 819380 D1=0.954139 D2=1.32371 D3+=1.38583\n",
            "4 848641 D1=0.985092 D2=1.50823 D3+=1.54378\n",
            "5 828240 D1=0.98618 D2=1.4225 D3+=1.7097\n",
            "Memory estimate for binary LM:\n",
            "type    MB\n",
            "probing 69 assuming -p 1.5\n",
            "probing 82 assuming -r models -p 1.5\n",
            "trie    35 without quantization\n",
            "trie    20 assuming -q 8 -b 8 quantization \n",
            "trie    31 assuming -a 22 array pointer compression\n",
            "trie    16 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:1581924 2:9617472 3:16387600 4:20367384 5:23190720\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:1581924 2:9617472 3:16387600 4:20367384 5:23190720\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:10807256 kB\tVmRSS:10940 kB\tRSSMax:1926476 kB\tuser:5.63203\tsys:5.23839\tCPU:10.8705\treal:15.7249\n",
            "\n",
            "Processing: bg\n",
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_bg.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Unigram tokens 769928 types 92172\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:1106064 2:1062391040 3:1991983360 4:3187173120 5:4647961088\n",
            "Statistics:\n",
            "1 92172 D1=0.696386 D2=1.0449 D3+=1.43616\n",
            "2 389781 D1=0.820446 D2=1.15305 D3+=1.4053\n",
            "3 606588 D1=0.919815 D2=1.26422 D3+=1.38959\n",
            "4 673084 D1=0.964073 D2=1.35144 D3+=1.50424\n",
            "5 670028 D1=0.977272 D2=1.39222 D3+=1.59283\n",
            "Memory estimate for binary LM:\n",
            "type    MB\n",
            "probing 51 assuming -p 1.5\n",
            "probing 61 assuming -r models -p 1.5\n",
            "trie    25 without quantization\n",
            "trie    14 assuming -q 8 -b 8 quantization \n",
            "trie    23 assuming -a 22 array pointer compression\n",
            "trie    12 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:1106064 2:6236496 3:12131760 4:16154016 5:18760784\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:1106064 2:6236496 3:12131760 4:16154016 5:18760784\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:10807260 kB\tVmRSS:9188 kB\tRSSMax:1921968 kB\tuser:5.22625\tsys:9.04113\tCPU:14.2674\treal:20.1798\n",
            "\n",
            "Processing: ca\n",
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_ca.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Unigram tokens 1016278 types 87149\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:1045788 2:1062396992 3:1991994368 4:3187190784 5:4647987200\n",
            "Statistics:\n",
            "1 87149 D1=0.683073 D2=1.06417 D3+=1.42181\n",
            "2 424748 D1=0.810059 D2=1.15063 D3+=1.47088\n",
            "3 733680 D1=0.906164 D2=1.23966 D3+=1.46084\n",
            "4 853458 D1=0.960862 D2=1.35631 D3+=1.46058\n",
            "5 867567 D1=0.97187 D2=1.30177 D3+=1.34828\n",
            "Memory estimate for binary LM:\n",
            "type    MB\n",
            "probing 63 assuming -p 1.5\n",
            "probing 74 assuming -r models -p 1.5\n",
            "trie    30 without quantization\n",
            "trie    17 assuming -q 8 -b 8 quantization \n",
            "trie    27 assuming -a 22 array pointer compression\n",
            "trie    14 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:1045788 2:6795968 3:14673600 4:20482992 5:24291876\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:1045788 2:6795968 3:14673600 4:20482992 5:24291876\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:10807256 kB\tVmRSS:9104 kB\tRSSMax:1926848 kB\tuser:4.45052\tsys:5.29797\tCPU:9.74852\treal:12.3084\n",
            "\n",
            "Processing: cs\n",
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_cs.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Unigram tokens 713739 types 119848\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:1438176 2:1062358720 3:1991922688 4:3187076096 5:4647819776\n",
            "Statistics:\n",
            "1 119848 D1=0.707977 D2=1.05704 D3+=1.42264\n",
            "2 467138 D1=0.869376 D2=1.19033 D3+=1.41689\n",
            "3 627411 D1=0.949413 D2=1.2855 D3+=1.31016\n",
            "4 650458 D1=0.981252 D2=1.44034 D3+=1.38422\n",
            "5 626195 D1=0.988603 D2=1.50735 D3+=1.58439\n",
            "Memory estimate for binary LM:\n",
            "type    MB\n",
            "probing 53 assuming -p 1.5\n",
            "probing 64 assuming -r models -p 1.5\n",
            "trie    27 without quantization\n",
            "trie    15 assuming -q 8 -b 8 quantization \n",
            "trie    24 assuming -a 22 array pointer compression\n",
            "trie    12 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:1438176 2:7474208 3:12548220 4:15610992 5:17533460\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:1438176 2:7474208 3:12548220 4:15610992 5:17533460\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:10807256 kB\tVmRSS:9860 kB\tRSSMax:1920820 kB\tuser:3.61743\tsys:2.69583\tCPU:6.31331\treal:8.45835\n",
            "\n",
            "Processing: da\n",
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_da.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Unigram tokens 786056 types 94580\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:1134960 2:1062388288 3:1991978112 4:3187164928 5:4647948800\n",
            "Statistics:\n",
            "1 94580 D1=0.712538 D2=1.07216 D3+=1.44683\n",
            "2 420698 D1=0.837383 D2=1.16651 D3+=1.41814\n",
            "3 652698 D1=0.925584 D2=1.26622 D3+=1.34606\n",
            "4 713291 D1=0.972441 D2=1.40241 D3+=1.45368\n",
            "5 699450 D1=0.986987 D2=1.55712 D3+=1.67247\n",
            "Memory estimate for binary LM:\n",
            "type    MB\n",
            "probing 55 assuming -p 1.5\n",
            "probing 65 assuming -r models -p 1.5\n",
            "trie    27 without quantization\n",
            "trie    15 assuming -q 8 -b 8 quantization \n",
            "trie    24 assuming -a 22 array pointer compression\n",
            "trie    12 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:1134960 2:6731168 3:13053960 4:17118984 5:19584600\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:1134960 2:6731168 3:13053960 4:17118984 5:19584600\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:10807260 kB\tVmRSS:9480 kB\tRSSMax:1922812 kB\tuser:3.38603\tsys:2.46344\tCPU:5.84951\treal:7.24173\n",
            "\n",
            "Processing: de\n",
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_de.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Unigram tokens 737869 types 102130\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:1225560 2:1062379456 3:1991961600 4:3187138560 5:4647910400\n",
            "Statistics:\n",
            "1 102130 D1=0.719584 D2=1.07742 D3+=1.36591\n",
            "2 422527 D1=0.856975 D2=1.15706 D3+=1.35714\n",
            "3 629396 D1=0.938367 D2=1.26839 D3+=1.42613\n",
            "4 672420 D1=0.979285 D2=1.37277 D3+=1.61486\n",
            "5 651951 D1=0.990433 D2=1.5347 D3+=1.56084\n",
            "Memory estimate for binary LM:\n",
            "type    MB\n",
            "probing 53 assuming -p 1.5\n",
            "probing 63 assuming -r models -p 1.5\n",
            "trie    26 without quantization\n",
            "trie    15 assuming -q 8 -b 8 quantization \n",
            "trie    23 assuming -a 22 array pointer compression\n",
            "trie    12 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:1225560 2:6760432 3:12587920 4:16138080 5:18254628\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:1225560 2:6760432 3:12587920 4:16138080 5:18254628\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:10807256 kB\tVmRSS:9284 kB\tRSSMax:1921496 kB\tuser:3.52645\tsys:2.93104\tCPU:6.45754\treal:8.8328\n",
            "\n",
            "Processing: el\n",
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_el.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Unigram tokens 901230 types 101285\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:1215420 2:1062380352 3:1991963392 4:3187141120 5:4647914496\n",
            "Statistics:\n",
            "1 101285 D1=0.682358 D2=1.08534 D3+=1.43015\n",
            "2 451004 D1=0.823921 D2=1.15198 D3+=1.45173\n",
            "3 735626 D1=0.917171 D2=1.25498 D3+=1.41621\n",
            "4 817060 D1=0.969121 D2=1.42337 D3+=1.56205\n",
            "5 809192 D1=0.984674 D2=1.51477 D3+=1.48453\n",
            "Memory estimate for binary LM:\n",
            "type    MB\n",
            "probing 62 assuming -p 1.5\n",
            "probing 74 assuming -r models -p 1.5\n",
            "trie    30 without quantization\n",
            "trie    17 assuming -q 8 -b 8 quantization \n",
            "trie    27 assuming -a 22 array pointer compression\n",
            "trie    14 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:1215420 2:7216064 3:14712520 4:19609440 5:22657376\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:1215420 2:7216064 3:14712520 4:19609440 5:22657376\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:10807256 kB\tVmRSS:9440 kB\tRSSMax:1926100 kB\tuser:4.24348\tsys:2.22083\tCPU:6.4644\treal:10.2652\n",
            "\n",
            "Processing: en\n",
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_en.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Unigram tokens 903131 types 73935\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:887220 2:1062412480 3:1992023424 4:3187237376 5:4648054784\n",
            "Statistics:\n",
            "1 73935 D1=0.673182 D2=1.06377 D3+=1.39261\n",
            "2 434841 D1=0.815899 D2=1.13216 D3+=1.38626\n",
            "3 728259 D1=0.916444 D2=1.23775 D3+=1.3817\n",
            "4 817481 D1=0.969796 D2=1.39827 D3+=1.43236\n",
            "5 810985 D1=0.986079 D2=1.50922 D3+=1.64191\n",
            "Memory estimate for binary LM:\n",
            "type    MB\n",
            "probing 61 assuming -p 1.5\n",
            "probing 72 assuming -r models -p 1.5\n",
            "trie    29 without quantization\n",
            "trie    16 assuming -q 8 -b 8 quantization \n",
            "trie    26 assuming -a 22 array pointer compression\n",
            "trie    13 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:887220 2:6957456 3:14565180 4:19619544 5:22707580\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:887220 2:6957456 3:14565180 4:19619544 5:22707580\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:10807260 kB\tVmRSS:8848 kB\tRSSMax:1925812 kB\tuser:3.75215\tsys:2.1702\tCPU:5.92239\treal:7.73394\n",
            "\n",
            "Processing: es\n",
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_es.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Unigram tokens 1076290 types 89801\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:1077612 2:1062393856 3:1991988608 4:3187181568 5:4647973376\n",
            "Statistics:\n",
            "1 89801 D1=0.675762 D2=1.05632 D3+=1.42788\n",
            "2 456405 D1=0.806786 D2=1.13913 D3+=1.38469\n",
            "3 813309 D1=0.903567 D2=1.21376 D3+=1.31951\n",
            "4 953558 D1=0.961038 D2=1.33678 D3+=1.41177\n",
            "5 970420 D1=0.981755 D2=1.4396 D3+=1.52331\n",
            "Memory estimate for binary LM:\n",
            "type    MB\n",
            "probing 69 assuming -p 1.5\n",
            "probing 82 assuming -r models -p 1.5\n",
            "trie    34 without quantization\n",
            "trie    19 assuming -q 8 -b 8 quantization \n",
            "trie    30 assuming -a 22 array pointer compression\n",
            "trie    15 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:1077612 2:7302480 3:16266180 4:22885392 5:27171760\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:1077612 2:7302480 3:16266180 4:22885392 5:27171760\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:10807260 kB\tVmRSS:9216 kB\tRSSMax:1929932 kB\tuser:4.34491\tsys:2.35444\tCPU:6.6994\treal:8.76361\n",
            "\n",
            "Processing: et\n",
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_et.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Unigram tokens 600248 types 120536\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:1446432 2:1062357888 3:1991921152 4:3187073792 5:4647816192\n",
            "Statistics:\n",
            "1 120536 D1=0.739727 D2=1.06715 D3+=1.43452\n",
            "2 413395 D1=0.888874 D2=1.22808 D3+=1.37923\n",
            "3 528886 D1=0.949529 D2=1.2897 D3+=1.30869\n",
            "4 542890 D1=0.981244 D2=1.41424 D3+=1.59795\n",
            "5 516555 D1=0.989195 D2=1.54671 D3+=1.73346\n",
            "Memory estimate for binary LM:\n",
            "type    MB\n",
            "probing 45 assuming -p 1.5\n",
            "probing 54 assuming -r models -p 1.5\n",
            "trie    23 without quantization\n",
            "trie    13 assuming -q 8 -b 8 quantization \n",
            "trie    21 assuming -a 22 array pointer compression\n",
            "trie    11 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:1446432 2:6614320 3:10577720 4:13029360 5:14463540\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:1446432 2:6614320 3:10577720 4:13029360 5:14463540\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:10807256 kB\tVmRSS:9704 kB\tRSSMax:1918388 kB\tuser:3.16432\tsys:2.36269\tCPU:5.52705\treal:8.87822\n",
            "\n",
            "Processing: fa\n",
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_fa.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Unigram tokens 865883 types 67908\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:814896 2:1062419520 3:1992036736 4:3187258624 5:4648086016\n",
            "Statistics:\n",
            "1 67908 D1=0.707765 D2=0.998445 D3+=1.22028\n",
            "2 432098 D1=0.823002 D2=1.15263 D3+=1.39021\n",
            "3 698082 D1=0.929126 D2=1.30499 D3+=1.40077\n",
            "4 771462 D1=0.97415 D2=1.38688 D3+=1.4077\n",
            "5 765596 D1=0.985486 D2=1.5107 D3+=1.60496\n",
            "Memory estimate for binary LM:\n",
            "type    MB\n",
            "probing 58 assuming -p 1.5\n",
            "probing 69 assuming -r models -p 1.5\n",
            "trie    28 without quantization\n",
            "trie    15 assuming -q 8 -b 8 quantization \n",
            "trie    25 assuming -a 22 array pointer compression\n",
            "trie    12 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:814896 2:6913568 3:13961640 4:18515088 5:21436688\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:814896 2:6913568 3:13961640 4:18515088 5:21436688\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:10807256 kB\tVmRSS:8872 kB\tRSSMax:1924528 kB\tuser:3.72338\tsys:2.13269\tCPU:5.85611\treal:8.13471\n",
            "\n",
            "Processing: fi\n",
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_fi.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Unigram tokens 551125 types 130189\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:1562268 2:1062346624 3:1991900032 4:3187039744 5:4647766528\n",
            "Statistics:\n",
            "1 130189 D1=0.753192 D2=1.09088 D3+=1.41228\n",
            "2 398465 D1=0.90244 D2=1.21969 D3+=1.37231\n",
            "3 494412 D1=0.958392 D2=1.28148 D3+=1.23999\n",
            "4 497677 D1=0.985029 D2=1.43156 D3+=1.51698\n",
            "5 467848 D1=0.990928 D2=1.56435 D3+=1.25952\n",
            "Memory estimate for binary LM:\n",
            "type    MB\n",
            "probing 43 assuming -p 1.5\n",
            "probing 51 assuming -r models -p 1.5\n",
            "trie    22 without quantization\n",
            "trie    13 assuming -q 8 -b 8 quantization \n",
            "trie    20 assuming -a 22 array pointer compression\n",
            "trie    11 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:1562268 2:6375440 3:9888240 4:11944248 5:13099744\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:1562268 2:6375440 3:9888240 4:11944248 5:13099744\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:10807252 kB\tVmRSS:9964 kB\tRSSMax:1917460 kB\tuser:2.76835\tsys:1.99195\tCPU:4.76035\treal:5.94439\n",
            "\n",
            "Processing: fr\n",
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_fr.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Unigram tokens 959648 types 85735\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:1028820 2:1062398656 3:1991997568 4:3187195904 5:4647994368\n",
            "Statistics:\n",
            "1 85735 D1=0.673212 D2=1.0854 D3+=1.40043\n",
            "2 434302 D1=0.808375 D2=1.14439 D3+=1.38762\n",
            "3 752313 D1=0.907685 D2=1.24301 D3+=1.40108\n",
            "4 857458 D1=0.963926 D2=1.38279 D3+=1.54949\n",
            "5 859661 D1=0.98202 D2=1.39342 D3+=1.7602\n",
            "Memory estimate for binary LM:\n",
            "type    MB\n",
            "probing 63 assuming -p 1.5\n",
            "probing 75 assuming -r models -p 1.5\n",
            "trie    31 without quantization\n",
            "trie    17 assuming -q 8 -b 8 quantization \n",
            "trie    28 assuming -a 22 array pointer compression\n",
            "trie    14 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:1028820 2:6948832 3:15046260 4:20578992 5:24070508\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:1028820 2:6948832 3:15046260 4:20578992 5:24070508\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:10807256 kB\tVmRSS:9080 kB\tRSSMax:1926488 kB\tuser:4.21198\tsys:2.15802\tCPU:6.37003\treal:8.68243\n",
            "\n",
            "Processing: he\n",
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_he.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Unigram tokens 759522 types 111480\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:1337760 2:1062368512 3:1991940992 4:3187105536 5:4647862272\n",
            "Statistics:\n",
            "1 111480 D1=0.679132 D2=1.03007 D3+=1.4144\n",
            "2 510483 D1=0.863064 D2=1.20248 D3+=1.38739\n",
            "3 680733 D1=0.953254 D2=1.30341 D3+=1.38003\n",
            "4 699904 D1=0.984499 D2=1.40551 D3+=1.41331\n",
            "5 674331 D1=0.992718 D2=1.47964 D3+=1.45782\n",
            "Memory estimate for binary LM:\n",
            "type    MB\n",
            "probing 57 assuming -p 1.5\n",
            "probing 68 assuming -r models -p 1.5\n",
            "trie    28 without quantization\n",
            "trie    16 assuming -q 8 -b 8 quantization \n",
            "trie    26 assuming -a 22 array pointer compression\n",
            "trie    13 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:1337760 2:8167728 3:13614660 4:16797696 5:18881268\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:1337760 2:8167728 3:13614660 4:16797696 5:18881268\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:10807252 kB\tVmRSS:9484 kB\tRSSMax:1922252 kB\tuser:3.771\tsys:2.24861\tCPU:6.01965\treal:8.51107\n",
            "\n",
            "Processing: hi\n",
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_hi.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Unigram tokens 831687 types 66139\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:793668 2:1062421568 3:1992040448 4:3187264512 5:4648094720\n",
            "Statistics:\n",
            "1 66139 D1=0.707468 D2=1.01353 D3+=1.30422\n",
            "2 379713 D1=0.801671 D2=1.14658 D3+=1.44859\n",
            "3 637890 D1=0.91305 D2=1.27568 D3+=1.45\n",
            "4 718712 D1=0.963862 D2=1.33661 D3+=1.4409\n",
            "5 725890 D1=0.977872 D2=1.4553 D3+=1.36088\n",
            "Memory estimate for binary LM:\n",
            "type    MB\n",
            "probing 53 assuming -p 1.5\n",
            "probing 64 assuming -r models -p 1.5\n",
            "trie    26 without quantization\n",
            "trie    14 assuming -q 8 -b 8 quantization \n",
            "trie    23 assuming -a 22 array pointer compression\n",
            "trie    12 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:793668 2:6075408 3:12757800 4:17249088 5:20324920\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:793668 2:6075408 3:12757800 4:17249088 5:20324920\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "----------------------------------------------------------------------------------------------------Last input should have been poison.  The program should end soon with an error.  If it doesn't, there's a bug.\n",
            "terminate called after throwing an instance of 'util::FDException'\n",
            "  what():  /content/kenlm/build/kenlm/util/file.cc:228 in void util::WriteOrThrow(int, const void*, std::size_t) threw FDException because `ret < 1'.\n",
            "Transport endpoint is not connected in /MyDrive/Multilingual_NLP/Lab_1/kenlm/arpa_files/hi.arpa while writing 8184 bytes\n",
            "/bin/bash: line 1: 80065 Aborted                 (core dumped) ./bin/lmplz -o 5 < /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_hi.txt > /content/drive/MyDrive/Multilingual_NLP/Lab_1/kenlm/arpa_files/hi.arpa\n",
            "\n",
            "Processing: hr\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_hr.txt: No such file or directory\n",
            "\n",
            "Processing: hu\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_hu.txt: No such file or directory\n",
            "\n",
            "Processing: id\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_id.txt: No such file or directory\n",
            "\n",
            "Processing: it\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_it.txt: No such file or directory\n",
            "\n",
            "Processing: ja\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_ja.txt: No such file or directory\n",
            "\n",
            "Processing: ko\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_ko.txt: No such file or directory\n",
            "\n",
            "Processing: lt\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_lt.txt: No such file or directory\n",
            "\n",
            "Processing: lv\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_lv.txt: No such file or directory\n",
            "\n",
            "Processing: ms\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_ms.txt: No such file or directory\n",
            "\n",
            "Processing: nl\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_nl.txt: No such file or directory\n",
            "\n",
            "Processing: no\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_no.txt: No such file or directory\n",
            "\n",
            "Processing: pl\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_pl.txt: No such file or directory\n",
            "\n",
            "Processing: pt\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_pt.txt: No such file or directory\n",
            "\n",
            "Processing: ro\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_ro.txt: No such file or directory\n",
            "\n",
            "Processing: ru\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_ru.txt: No such file or directory\n",
            "\n",
            "Processing: sk\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_sk.txt: No such file or directory\n",
            "\n",
            "Processing: sl\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_sl.txt: No such file or directory\n",
            "\n",
            "Processing: sr\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_sr.txt: No such file or directory\n",
            "\n",
            "Processing: sv\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_sv.txt: No such file or directory\n",
            "\n",
            "Processing: th\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_th.txt: No such file or directory\n",
            "\n",
            "Processing: tl\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_tl.txt: No such file or directory\n",
            "\n",
            "Processing: tr\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_tr.txt: No such file or directory\n",
            "\n",
            "Processing: uk\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_uk.txt: No such file or directory\n",
            "\n",
            "Processing: vi\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_vi.txt: No such file or directory\n",
            "\n",
            "Processing: zh-cn\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_zh-cn.txt: No such file or directory\n",
            "\n",
            "Processing: zh-tw\n",
            "/bin/bash: line 1: /content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_zh-tw.txt: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_perplexity(model, datasets):\n",
        "  pp_all_sentences = [model.perplexity(sentence) for sentence in datasets]\n",
        "  return statistics.mean(pp_all_sentences)"
      ],
      "metadata": {
        "id": "QEm1XfBOY0Ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity_dict_kenlm= {}\n",
        "perplexity_list_kenlm = []\n",
        "for lang in lang_codes:\n",
        "    print(\"Precessing: \", lang)\n",
        "    model = kenlm.Model(f'/content/drive/MyDrive/Multilingual_NLP/Lab_1/kenlm/arpa_files/{lang}.arpa')\n",
        "\n",
        "    # Iteration in the test set to get the mean perplexity\n",
        "    perplexity_dict_kenlm[lang] = compute_perplexity(model, test_sets[lang])\n",
        "    perplexity_list_kenlm.append(compute_perplexity(model, test_sets[lang]))\n",
        "    #print(f'Perplexity for {lang}: {perplexity_dict[lang]}')\n",
        "\n",
        "all_data[\"perplexity kenlm\"] = perplexity_list_kenlm\n",
        "all_data"
      ],
      "metadata": {
        "id": "3-tQEsZ8YzU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity_list_kenlm"
      ],
      "metadata": {
        "id": "I091PFwTTqB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFtSHjqok423"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To ensure that all language have the same vocabulary size, we can consider the BPE tokenization."
      ],
      "metadata": {
        "id": "5dd34W1pRxIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.scatterplot(data=all_data, x=\"ttr\", y=\"perplexity kenlm\", hue =\"morphology\")\n",
        "all_data.apply(lambda x: ax.text (x['ttr'] -0.005 , x['perplexity kenlm']+300 , x['languages']), axis=1)"
      ],
      "metadata": {
        "id": "cgbaKpaYbcle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp_tokenization_dir = \"/content/drive/MyDrive/Multilingual_NLP/Lab_1/sentencepiece_tokenization/\""
      ],
      "metadata": {
        "id": "kAZqnPM2alBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "id": "-sct8qYwGjf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fcc5dfb8-dbaf-4db9-fb52-81ba628c4bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/kenlm/build/kenlm/build'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_perplexity(sentences, kenlm_model, sp):\n",
        "    total_log_prob = 0.0\n",
        "    total_words = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        # Tokenize the sentence using SentencePiece\n",
        "        tokens = sp.encode_as_pieces(sentence.strip())\n",
        "        tokenized_sentence = ' '.join(tokens)\n",
        "\n",
        "        # Calculate log probability (negative log likelihood) using KenLM\n",
        "        log_prob = kenlm_model.score(tokenized_sentence, bos=True, eos=True)\n",
        "        total_log_prob += log_prob\n",
        "        total_words += len(tokens)\n",
        "\n",
        "    # Calculate perplexity as exponent of the average log probability\n",
        "    avg_log_prob = total_log_prob / total_words\n",
        "    perplexity = 10 ** (-avg_log_prob)\n",
        "\n",
        "    return perplexity"
      ],
      "metadata": {
        "id": "0Y69jtPgVzku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_sp_model(sentence_file, lang, vocab_size):\n",
        "    # Train SentencePiece model\n",
        "    try:\n",
        "      spm.SentencePieceTrainer.train(input=sentences_file, model_prefix=f'tokenizer_{lang}', vocab_size=vocab_size)\n",
        "    except RuntimeError as e:\n",
        "      # Parse the exception message to extract the max vocab size\n",
        "      error_message = str(e)\n",
        "      max_vocab_size = int((error_message.split(\" \")[-1]).rstrip('.'))\n",
        "      spm.SentencePieceTrainer.train(input=sentences_file, model_prefix=f'tokenizer_{lang}', vocab_size=max_vocab_size)\n",
        "      print(f\"Reducing vocab size to {max_vocab_size} for {lang} due to error.\")\n",
        "\n",
        "    # Load the trained SentencePiece model\n",
        "    sp = spm.SentencePieceProcessor(model_file=f'tokenizer_{lang}.model')\n",
        "    return sp"
      ],
      "metadata": {
        "id": "HAtmzl5vvvvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity_dict_sp= {}\n",
        "perplexity_list_sp = []\n",
        "\n",
        "for lang in lang_codes:\n",
        "    print(\"Processing:\", lang)\n",
        "    sentences_file = f'/content/drive/MyDrive/Multilingual_NLP/Lab_1/tokenized_sentences/train_{lang}.txt'\n",
        "\n",
        "    sp = train_sp_model(sentences_file, lang, 32_000)\n",
        "    # Tokenize each sentence and write to the output file\n",
        "    with open(os.path.join(sp_tokenization_dir, f\"tokenized_{lang}.txt\"), \"w\", encoding=\"utf-8\") as output_file:\n",
        "        with open(sentences_file, \"r\", encoding=\"utf-8\") as input_file:\n",
        "            for sentence in input_file:\n",
        "                tokens = sp.encode_as_pieces(sentence.strip())\n",
        "                output_file.write(\" \".join(tokens) + \"\\n\")\n",
        "    # Compute the new perplexity\n",
        "    perplexity_dict_sp[lang] = calculate_perplexity(test_sets[lang], model, sp)\n",
        "\n",
        "    perplexity_list_sp.append(calculate_perplexity(test_sets[lang], model, sp))\n",
        "all_data[\"perplexity sp\"] = perplexity_list_sp\n",
        "all_data"
      ],
      "metadata": {
        "id": "Yvwz248hdVYR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af7f44ff-6b2f-4233-c1ff-5521cd9194fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: ar\n",
            "Processing: bg\n",
            "Processing: ca\n",
            "Processing: cs\n",
            "Processing: da\n",
            "Processing: de\n",
            "Processing: el\n",
            "Processing: en\n",
            "Processing: es\n",
            "Processing: et\n",
            "Processing: fa\n",
            "Reducing vocab size to 31586 for fa due to error.\n",
            "Processing: fi\n",
            "Processing: fr\n",
            "Processing: he\n",
            "Processing: hi\n",
            "Processing: hr\n",
            "Processing: hu\n",
            "Processing: id\n",
            "Processing: it\n",
            "Processing: ja\n",
            "Reducing vocab size to 27279 for ja due to error.\n",
            "Processing: ko\n",
            "Processing: lt\n",
            "Processing: lv\n",
            "Processing: ms\n",
            "Processing: nl\n",
            "Processing: no\n",
            "Processing: pl\n",
            "Processing: pt\n",
            "Processing: ro\n",
            "Processing: ru\n",
            "Processing: sk\n",
            "Processing: sl\n",
            "Processing: sr\n",
            "Processing: sv\n",
            "Processing: th\n",
            "Processing: tl\n",
            "Processing: tr\n",
            "Processing: uk\n",
            "Processing: vi\n",
            "Reducing vocab size to 25991 for vi due to error.\n",
            "Processing: zh-cn\n",
            "Reducing vocab size to 22117 for zh-cn due to error.\n",
            "Processing: zh-tw\n",
            "Reducing vocab size to 23803 for zh-tw due to error.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   languages  perplexity sp\n",
              "0         ar  338131.081377\n",
              "1         bg  195721.769176\n",
              "2         ca  132491.743424\n",
              "3         cs  146613.407687\n",
              "4         da  143683.856794\n",
              "5         de  119179.149813\n",
              "6         el  229800.429064\n",
              "7         en  160305.654487\n",
              "8         es  172836.449935\n",
              "9         et  131588.601844\n",
              "10        fa  337885.733717\n",
              "11        fi  127921.439593\n",
              "12        fr  150840.908057\n",
              "13        he  198959.097811\n",
              "14        hi  389685.242964\n",
              "15        hr  119742.532820\n",
              "16        hu  127344.576319\n",
              "17        id  160258.181831\n",
              "18        it  148590.129640\n",
              "19        ja  414236.537309\n",
              "20        ko  227548.906271\n",
              "21        lt  112287.542098\n",
              "22        lv  104903.628590\n",
              "23        ms  171062.806459\n",
              "24        nl  168613.202191\n",
              "25        no  155223.001834\n",
              "26        pl  132193.014990\n",
              "27        pt  154396.139012\n",
              "28        ro  135209.806708\n",
              "29        ru  205405.894942\n",
              "30        sk  140768.806328\n",
              "31        sl  135506.961868\n",
              "32        sr  204382.675773\n",
              "33        sv  147286.159535\n",
              "34        th  393954.746081\n",
              "35        tl  192670.934255\n",
              "36        tr  146389.382923\n",
              "37        uk  184895.105397\n",
              "38        vi  208637.056503\n",
              "39     zh-cn  285559.379991\n",
              "40     zh-tw  288932.346404"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c4f6367-80d4-48d1-9790-c046abc3d981\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>languages</th>\n",
              "      <th>perplexity sp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ar</td>\n",
              "      <td>338131.081377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bg</td>\n",
              "      <td>195721.769176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ca</td>\n",
              "      <td>132491.743424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cs</td>\n",
              "      <td>146613.407687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>da</td>\n",
              "      <td>143683.856794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>de</td>\n",
              "      <td>119179.149813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>el</td>\n",
              "      <td>229800.429064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>en</td>\n",
              "      <td>160305.654487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>es</td>\n",
              "      <td>172836.449935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>et</td>\n",
              "      <td>131588.601844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>fa</td>\n",
              "      <td>337885.733717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>fi</td>\n",
              "      <td>127921.439593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>fr</td>\n",
              "      <td>150840.908057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>he</td>\n",
              "      <td>198959.097811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>hi</td>\n",
              "      <td>389685.242964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>hr</td>\n",
              "      <td>119742.532820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>hu</td>\n",
              "      <td>127344.576319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>id</td>\n",
              "      <td>160258.181831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>it</td>\n",
              "      <td>148590.129640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>ja</td>\n",
              "      <td>414236.537309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>ko</td>\n",
              "      <td>227548.906271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>lt</td>\n",
              "      <td>112287.542098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>lv</td>\n",
              "      <td>104903.628590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ms</td>\n",
              "      <td>171062.806459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>nl</td>\n",
              "      <td>168613.202191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>no</td>\n",
              "      <td>155223.001834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>pl</td>\n",
              "      <td>132193.014990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>pt</td>\n",
              "      <td>154396.139012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>ro</td>\n",
              "      <td>135209.806708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>ru</td>\n",
              "      <td>205405.894942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>sk</td>\n",
              "      <td>140768.806328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>sl</td>\n",
              "      <td>135506.961868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>sr</td>\n",
              "      <td>204382.675773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>sv</td>\n",
              "      <td>147286.159535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>th</td>\n",
              "      <td>393954.746081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>tl</td>\n",
              "      <td>192670.934255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>tr</td>\n",
              "      <td>146389.382923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>uk</td>\n",
              "      <td>184895.105397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>vi</td>\n",
              "      <td>208637.056503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>zh-cn</td>\n",
              "      <td>285559.379991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>zh-tw</td>\n",
              "      <td>288932.346404</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c4f6367-80d4-48d1-9790-c046abc3d981')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7c4f6367-80d4-48d1-9790-c046abc3d981 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7c4f6367-80d4-48d1-9790-c046abc3d981');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-66cc2792-73cc-44db-9183-ba3daef35a00\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-66cc2792-73cc-44db-9183-ba3daef35a00')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-66cc2792-73cc-44db-9183-ba3daef35a00 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store TTR values for each dataset\n",
        "ttr_values_sp = {}\n",
        "ttr_list_sp = []\n",
        "\n",
        "# Iterate through the files in the input directory\n",
        "for lang in lang_codes:\n",
        "    # Read the content of the file and tokenize it\n",
        "    with open(os.path.join(input_dir, f\"train_{lang}.txt\"), \"r\", encoding=\"utf-8\") as file:\n",
        "        content_sp = file.read()\n",
        "        tokens_sp = content_sp.split()  # Split by whitespace\n",
        "\n",
        "        # Calculate TTR for the dataset\n",
        "        ttr_sp = calculate_ttr(tokens_sp)\n",
        "        # Store TTR value in the dictionary\n",
        "        ttr_values_sp[lang] = ttr_sp\n",
        "        ttr_list_sp.append(ttr_sp)\n",
        "\n",
        "ttr_list_sp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU0a2jMX2n4Q",
        "outputId": "9bdb3f84-5be7-48a5-ad16-79ad705767f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.14002885046409308,\n",
              " 0.11971119377396328,\n",
              " 0.08575015891321075,\n",
              " 0.1679115194770077,\n",
              " 0.12031839970689111,\n",
              " 0.138408037199015,\n",
              " 0.11237937359151295,\n",
              " 0.08186187828786742,\n",
              " 0.08343290377128841,\n",
              " 0.20080533379536458,\n",
              " 0.07842283541771809,\n",
              " 0.23621864368337492,\n",
              " 0.08933692353863083,\n",
              " 0.14677257538293823,\n",
              " 0.07952030030528312,\n",
              " 0.1541908082916064,\n",
              " 0.17200491007041657,\n",
              " 0.09266767789347709,\n",
              " 0.09362649361034647,\n",
              " 0.052653000133916966,\n",
              " 0.2605423839571974,\n",
              " 0.16970516580983938,\n",
              " 0.1482282158288234,\n",
              " 0.08298029188289215,\n",
              " 0.10941018110621635,\n",
              " 0.12793471711385515,\n",
              " 0.167044200926675,\n",
              " 0.08312442554566848,\n",
              " 0.10055874749543331,\n",
              " 0.1668747532735168,\n",
              " 0.16775242602070065,\n",
              " 0.1474443717364178,\n",
              " 0.16442419509783543,\n",
              " 0.14027142216880814,\n",
              " 0.029789412728157875,\n",
              " 0.08941383771193188,\n",
              " 0.1803051873834493,\n",
              " 0.16583820057164161,\n",
              " 0.03788764021671778,\n",
              " 0.0487165808666213,\n",
              " 0.056661791431939224]"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ54gkeSk5Ut"
      },
      "outputs": [],
      "source": [
        "# Plot the results of the previous two sections to reproduce the result reported in Figure 1\n",
        "# Create a color map for morphological categories\n",
        "def plot_scatter_results(perplexity_dict, ttr_values, morphology_dict):\n",
        "  color_map = {\n",
        "      \"isolating\": \"blue\",\n",
        "      \"fusional\": \"orange\",\n",
        "      \"agglutinative\": \"green\",\n",
        "      \"introflexive\": \"red\",\n",
        "  }\n",
        "  # Create lists to store data for plotting\n",
        "  ttr_data = []\n",
        "  perplexity_data = []\n",
        "  colors = []\n",
        "  lang_labels = []\n",
        "\n",
        "  # Iterate through languages and gather data for plotting\n",
        "  for lang in perplexity_dict:\n",
        "      if lang in ttr_values and lang in morphology_dict:\n",
        "          ttr_data.append(ttr_values[lang])\n",
        "          perplexity_data.append(perplexity_dict[lang]/100) # / 20\n",
        "          colors.append(color_map[morphology_dict[lang]])\n",
        "          lang_labels.append(lang)  # Store lang_code values\n",
        "\n",
        "  # Create the scatter plot\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  scatter = plt.scatter(ttr_data, perplexity_data, c=colors)\n",
        "\n",
        "  # Annotate the scatter plot with lang_code labels\n",
        "  for i, lang in enumerate(lang_labels):\n",
        "      plt.annotate(lang, (ttr_data[i], perplexity_data[i]))\n",
        "\n",
        "  for label, color in color_map.items():\n",
        "      plt.scatter([], [], c=color, label=label)\n",
        "\n",
        "  plt.xlabel(\"TTR Score\")\n",
        "  plt.ylabel(\"Perplexity\")\n",
        "  plt.title(\"Perplexity vs. TTR Score by Morphology\")\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_scatter_results(perplexity_dict_sp, ttr_values_sp, morphology_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "HFnaNuUH3gA_",
        "outputId": "aa3a7220-af1c-4f0a-8619-aed3f48971da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "10m5J2qevB8Qi6TNxlboRE636eOtqTJRi",
      "authorship_tag": "ABX9TyPri6kSzLu9qzA6nmeY3G+n",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}